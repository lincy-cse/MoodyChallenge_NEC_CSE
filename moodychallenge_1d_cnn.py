# -*- coding: utf-8 -*-
"""MoodyChallenge-1D CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pyzo1V2XfzhFEaInUcy7XeWaMUgG507V
"""

import pandas as pd
df1=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Moody Challenge/Chagas1.csv')
df2=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Moody Challenge/ChagasLabel.csv')
merged_df = pd.merge(df1, df2, on='exam_id',how='left')
merged_df

merged_df["chagas"].fillna(False,inplace=True)
merged_df

train_X=merged_df.iloc[0:1000,0:7]
train_Y=merged_df.iloc[0:1000,7]
test_X=merged_df.iloc[1001:1610,0:7]
test_Y=merged_df.iloc[1001:1610,7]

train_X.head()
train_Y.head()
test_X.head()
test_Y.head()

import tensorflow as tf

from tensorflow.keras import datasets, layers, models
from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout

cnn_model = tf.keras.models.Sequential()
#First CNN layer  with 32 filters, conv window 3, relu activation and same padding
cnn_model.add(Conv1D(filters=32, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001), input_shape = (7,1)))
#Second CNN layer  with 64 filters, conv window 3, relu activation and same padding
cnn_model.add(Conv1D(filters=64, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))
#Third CNN layer with 128 filters, conv window 3, relu activation and same padding
cnn_model.add(Conv1D(filters=128, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))
#Fourth CNN layer with Max pooling
cnn_model.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))
cnn_model.add(Dropout(0.5))
#Flatten the output
cnn_model.add(Flatten())
#Add a dense layer with 256 neurons
cnn_model.add(Dense(units = 256, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))
#Add a dense layer with 512 neurons
cnn_model.add(Dense(units = 512, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))
#Softmax as last layer with five outputs
cnn_model.add(Dense(units = 2, activation='softmax'))

cnn_model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])

cnn_model.summary()

cnn_model_history = cnn_model.fit(train_X, train_Y, epochs=10, batch_size = 10, validation_data = (test_X, test_Y))

import matplotlib.pyplot as plt
plt.plot(cnn_model_history.history['accuracy'])
plt.plot(cnn_model_history.history['val_accuracy'])
plt.legend(["accuracy","val_accuracy"])
plt.title('Accuracy Vs Val_Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')